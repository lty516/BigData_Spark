(7) 스파크 
	1) 설치 
		- 프로그램 준비
			http://spark.apache/org
			http://spark.apache.org/downloads.html- <2.4.7버전/하둡 2.7기반 >다운
			https://www.apache.org/dyn/closer.lua/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz
			
			압축 풀기 : tar zxvf spark-2.4.7-bin-hadoop2.7.tgz
			설치폴더명은 spark로 변경 : mv spark-2.4.7-bin-hadoop2.7 spark
			압축파일 삭제 : rm spark-2.4.7-bin-hadoop2.7
		- 환경변수 설정
			gedit /etc/profile
			-------------------
			export SPARK_HOME=/root/spark
			export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
			-------------------
			source /etc/profile
			stop-dfs.sh
			stop-yarn.sh
			reboot

			하둡 켜지않고 대기

		- 환경변수 테스트
			spark-shell : scala언어 사용
				sc	: SparkContext
				spark	: SparkSeession
				3 + 4
				ctrl + c

			pyspark : python 언어 사용 
				sc
				spark
				3 + 4
				exit()
			spark-sql : sql언어 사용
				
	2) StandAlone 설치
		free -g 
		grep -c processor /proc/cpuinfo
		
		cd $SPARK_HOME/conf
		cp spark-env.sh.template spark-env.sh
		
		gedit spark-env.sh
		----------------------------
		export SPARK_WORKER_INSTANCES=3
		----------------------------

		start-master.sh 

		http://localhost:8080
		http://192.168.10.1:8080

		start-slave.sh spark://master:7070 -m 512m -c 1

		jps
		stop-slave.sh
		stop-master.sh

